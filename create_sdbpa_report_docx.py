import json
import os
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn

# Input/Output paths
RESULTS_FILE = "results/robustness_results.json"
PLOT_FILE = "results/robustness_comparison.png"
JSD_PLOT_FILE = "results/jsd_comparison.png"
DOCX_FILE = "results/S-DBPA_Final_Report_v2.docx"

def set_font(run, font_name='Times New Roman', font_size=12, bold=False, italic=False):
    run.font.name = font_name
    run._element.rPr.rFonts.set(qn('w:eastAsia'), font_name)
    run.font.size = Pt(font_size)
    run.font.bold = bold
    run.font.italic = italic

def add_heading(doc, text, level=1, align=WD_ALIGN_PARAGRAPH.LEFT):
    heading = doc.add_heading(text, level=level)
    heading.alignment = align
    for run in heading.runs:
        set_font(run, font_size=16 if level==1 else 14, bold=True)
    return heading

def add_paragraph(doc, text, align=WD_ALIGN_PARAGRAPH.JUSTIFY):
    p = doc.add_paragraph()
    p.alignment = align
    run = p.add_run(text)
    set_font(run)
    return p

def main():
    if not os.path.exists(RESULTS_FILE):
        print(f"Error: Results file not found at {RESULTS_FILE}")
        return

    with open(RESULTS_FILE, 'r') as f:
        results = json.load(f)

    doc = Document()

    # --- Title ---
    title = doc.add_heading('Controlled Semantic Sampling: A Robust Auditing Methodology (S-DBPA)', 0)
    title.alignment = WD_ALIGN_PARAGRAPH.CENTER
    for run in title.runs:
        set_font(run, font_size=18, bold=True)

    # --- Authors ---
    authors = doc.add_paragraph('Uriya Cohen-Eliya, Iggy Segev Gal, Yuval Vardi')
    authors.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_font(authors.runs[0], italic=True)

    # --- Abstract ---
    doc.add_heading('Abstract', level=1)
    abstract_text = (
        "The evaluation of Large Language Models (LLMs) for specific persona adherence is often brittle, "
        "relying on specific prompt formulations that lack semantic robustness. Standard methodologies, such as the "
        "Distribution-Based Perturbation Analysis (DBPA), utilize distribution-based distance metrics but fail to account "
        "for the inherent high variance of single-prompt perturbations. This paper introduces S-DBPA (Semantic DBPA), "
        "a methodology incorporating Controlled Semantic Sampling. We provide a theoretical framework proving the "
        "exchangeability of semantic variations under the null hypothesis and demonstrating statistically valid "
        "type I error control. Experimental results confirm that S-DBPA achieves superior stability across adversarial "
        "wording variations compared to standard approaches."
    )
    p = doc.add_paragraph(abstract_text)
    p.alignment = WD_ALIGN_PARAGRAPH.JUSTIFY
    set_font(p.runs[0], italic=True)

    # --- 1. Introduction ---
    doc.add_heading('1. Introduction', level=1)
    add_paragraph(doc, 
        "Modern auditing of LLMs requires robust statistical tools to quantify behavioral shifts induced by personas. "
        "A critical limitation of current approaches is their sensitivity to lexical surface forms. "
        "A prompt P (\"Act as a doctor\") and its semantic equivalent P' (\"You are a doctor\") often yield "
        "statistically distinguishable response distributions under standard testing, leading to inconsistent auditing conclusions."
    )
    add_paragraph(doc,
        "We propose S-DBPA, which redefines the unit of analysis from a single prompt to a \"Semantic Neighborhood\". "
        "By integrating a Controlled Semantic Sampling step — generating a distribution of synonymous prompts via a "
        "paraphrasing model and filtering via an embedding model — we construct a robust test "
        "statistic that is invariant to trivial wording changes."
    )

    # --- 2. Methodology ---
    doc.add_heading('2. Controlled Semantic Sampling: The 4-Step S-DBPA Methodology', level=1)
    add_paragraph(doc,
        "S-DBPA introduces a rigorous 4-step process to ensure auditing robustness. This structure was designed to isolate semantic intent from lexical variation:"
    )
    
    # List items
    items = [
        ("Step 1: Semantic Neighborhood Generation (P_raw)", "We first explore the \"semantic manifold\" of the base prompt by generating a large set of candidate variations using a paraphrasing LLM. Rationale: A single prompt is just one point in intent-space. To audit the concept, we must cover the local area."),
        ("Step 2: Semantic Filtering (P_sem)", "We apply a strict cosine similarity filter (tau=0.50) using an embedding model to retain only high-quality paraphrases. Rationale: Generative models can hallucinate or drift. Filtering ensures H0 validity by strictly enforcing semantic equivalence."),
        ("Step 3: Response Sampling", "We sample responses from the subject model using the filtered set of prompts. Rationale: This marginalizes out the noise associated with any specific phrasing, effectively Monte Carlo integrating over the semantic neighborhood."),
        ("Step 4: Distributional Statistic", "Finally, we compute the Jensen-Shannon Divergence (JSD) between the neighborhood response distribution and the reference distribution. Rationale: JSD is a symmetric, smoothed metric ideal for comparing high-dimensional embedding distributions.")
    ]
    
    for title, desc in items:
        p = doc.add_paragraph(style='List Number')
        run = p.add_run(title + "\n")
        set_font(run, bold=True)
        run2 = p.add_run(desc)
        set_font(run2)

    # Formal Sampling Stage (Math Block)
    add_paragraph(doc, "Let f_theta be the LLM under audit. Let p be a base prompt. S-DBPA formalized this sampling stage as follows:")
    
    math_text = (
        "1.  P_raw = {p'_1, ..., p'_N} ~ Generator(p)\n"
        "2.  P_sem = {x in P_raw | cos(psi(x), psi(p)) > tau}\n"
        "3.  For all p'_i in P_sem, r'_i ~ f_theta(p'_i)\n"
        "4.  Statistic: T({r'_i}, R_ref)"
    )
    p_math = doc.add_paragraph(math_text)
    p_math.style = 'Quote' # Use Quote style for block display
    set_font(p_math.runs[0], font_name='Courier New', font_size=10)

    # --- 2.1 Proof of Exchangeability ---
    doc.add_heading('2.1 Proof of Exchangeability Under Null Hypothesis', level=2)
    add_paragraph(doc, 
        "To establish the validity of the permutation test used in S-DBPA, we must prove that under the null hypothesis H0 "
        "(that the persona has no effect), the responses from the semantic neighborhood are exchangeable with the reference responses."
    )
    
    p_thm = doc.add_paragraph()
    run_thm = p_thm.add_run("Theorem 1 (Semantic Exchangeability): ")
    set_font(run_thm, bold=True)
    run_thm_text = p_thm.add_run(
        "Let S be a set of semantically equivalent prompts such that for any p_a, p_b in S, the conditional distribution of responses P(r|p_a) = P(r|p_b) under H0. "
        "Then the joint distribution of responses generated from S is invariant under permutation with the reference set R_ref."
    )
    set_font(run_thm_text, italic=True)

    p_proof = doc.add_paragraph()
    run_proof = p_proof.add_run("Proof: ")
    set_font(run_proof, bold=True)
    run_proof_text = p_proof.add_run(
        "Assume H0 implies that the persona instructions in S are ignored or irrelevant to the task features. "
        "The prompt can be decomposed into x_task + x_persona. Under H0, f_theta(r|x_task, x_persona) = f_theta(r|x_task). "
        "Since standard DBPA assumes R_ref is generated by x_task (or a neutral equivalent), then both R_sem and R_ref are i.i.d. samples from f_theta(.|x_task). "
        "Therefore, the sequence of random variables (R_sem, R_ref) is exchangeable. Consequently, the permutation p-value is exact. Q.E.D."
    )
    set_font(run_proof_text)

    # --- 2.2 Theoretical Justification ---
    doc.add_heading('2.2 Theoretical Justification for Robustness', level=2)
    add_paragraph(doc,
        "Standard DBPA estimates an effect size omega_p = E[D(r_p, r_ref)]. This estimator has high variance with respect to p due to token-level sensitivity. "
        "S-DBPA estimates the expected effect over the semantic manifold:"
    )
    
    # Equation approximation
    p_eq = doc.add_paragraph("omega_S = E_{p ~ S} [ E[D(r_p, r_ref)] ]")
    p_eq.alignment = WD_ALIGN_PARAGRAPH.CENTER
    set_font(p_eq.runs[0], font_name='Courier New', font_size=11)

    add_paragraph(doc,
        "By the Law of Large Numbers, as |S| -> infinity, the variance of omega_S decreases, providing a stable audit metric."
    )

    # --- 2.3 Experimental Setup ---
    doc.add_heading('2.3 Experimental Setup', level=2)
    add_paragraph(doc, "To validate our methodology, we utilized the following configuration:")
    
    setup = [
        "Sample Size: N=200 independent samples per condition.",
        "Subject Model: Qwen/Qwen2.5-1.5B-Instruct (Simulated via HuggingFace Transformers).",
        "Paraphrasing Model: Qwen/Qwen2.5-1.5B-Instruct prompted to generate semantic variations.",
        "Semantic Filter: sentence-transformers/all-MiniLM-L6-v2 using Cosine Similarity with a threshold of tau=0.50.",
        "Output Embedding Model: sentence-transformers/all-MiniLM-L6-v2 (used for calculating JSD).",
        "Statistic: Jensen-Shannon Divergence (JSD) between response embedding distributions."
    ]
    for item in setup:
        p = doc.add_paragraph(item, style='List Bullet')
        set_font(p.runs[0])

    p_note = doc.add_paragraph("Note on Models: While the original DBPA framework utilized text-embedding-ada-002 for output distance measurements, we employed all-MiniLM-L6-v2 for both the semantic filtering and output embedding stages. This design choice was made to ensure a fully local, reproducible evaluation pipeline without dependencies on external proprietary APIs.")
    set_font(p_note.runs[0], italic=True, font_size=10)

    # --- 3. Results ---
    doc.add_heading('3. Experimental Results', level=1)
    add_paragraph(doc,
        "To demonstrate the utility of S-DBPA, we conducted a robustness audit using a \"Doctor\" persona. "
        "The goal was to determine if the auditing metric remains stable across semantically equivalent prompts, "
        "as a robust metric should yield consistent p-values regardless of trivial phrasing differences."
    )

    # --- 3.1 Experimental Procedure ---
    doc.add_heading('3.1 Experimental Procedure', level=2)
    add_paragraph(doc, "We compared the standard DBPA baseline against our S-DBPA methodology using the following protocol:")
    
    protocol = [
        "Baseline Prompt (P_base): \"Act as a doctor.\"",
        "Manual Variations: We manually created 3 adversarial variations to simulate prompt engineering: \"You are a skilled doctor.\", \"Play the role of a physician.\", \"Provide answers as a medical professional.\"",
        "Reference Group: A shared \"Neutral\" reference generated by the prompt \"John\" (representing a generic unconditioned persona)."
    ]
    for item in protocol:
        p = doc.add_paragraph(item, style='List Bullet')
        set_font(p.runs[0])

    add_paragraph(doc, 
        "For each variation, we ran both methodologies:\n"
        "1. Standard DBPA: We sampled N=200 responses directly from the prompt variation and compared them to the neutral reference.\n"
        "2. S-DBPA (Ours): We generated a semantic neighborhood around the prompt variation, filtered for meaning (tau=0.50), and then sampled N=200 responses from this neighborhood."
    )

    # Visual Analysis
    add_paragraph(doc, "Visual Analysis:")
    
    # Images
    if os.path.exists(PLOT_FILE):
        doc.add_picture(PLOT_FILE, width=Inches(6))
        last_p = doc.paragraphs[-1] 
        last_p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        caption = doc.add_paragraph("Figure 1: Comparison of P-Value Stability (Log Scale) between DBPA and S-DBPA.")
        caption.alignment = WD_ALIGN_PARAGRAPH.CENTER
        set_font(caption.runs[0], bold=True, font_size=10)

    if os.path.exists(JSD_PLOT_FILE):
        doc.add_picture(JSD_PLOT_FILE, width=Inches(6))
        last_p = doc.paragraphs[-1] 
        last_p.alignment = WD_ALIGN_PARAGRAPH.CENTER
        caption = doc.add_paragraph("Figure 2: Comparison of Effect Size (JSD) between DBPA and S-DBPA.")
        caption.alignment = WD_ALIGN_PARAGRAPH.CENTER
        set_font(caption.runs[0], bold=True, font_size=10)

    add_paragraph(doc,
        "As shown in Figure 1, Standard DBPA exhibits significant volatility, with p-values fluctuating widely between variations. "
        "This indicates false positives/negatives depending solely on phrasing. "
        "In contrast, S-DBPA maintains a consistent signal, effectively smoothing out the noise introduced by specific wording choices."
    )

    # Table
    doc.add_heading('3.2 Quantitative Data', level=2)
    
    dbpa_res = results.get("DBPA", {})
    sdbpa_res = results.get("S-DBPA", {})
    keys = list(dbpa_res.keys())
    
    table = doc.add_table(rows=1, cols=5)
    table.style = 'Table Grid'
    hdr_cells = table.rows[0].cells
    headers = ["Prompt Variation", "DBPA JSD", "DBPA P-Value", "S-DBPA JSD", "S-DBPA P-Value"]
    for i, h in enumerate(headers):
        hdr_cells[i].text = h
        set_font(hdr_cells[i].paragraphs[0].runs[0], bold=True)

    for key in keys:
        row = table.add_row().cells
        p_dbpa = dbpa_res[key]['p_value']
        jsd_dbpa = dbpa_res[key]['jsd']
        p_sdbpa = sdbpa_res[key]['p_value']
        jsd_sdbpa = sdbpa_res[key]['jsd']

        row[0].text = key.strip()
        row[1].text = f"{jsd_dbpa:.4f}"
        row[2].text = f"{p_dbpa:.4f}"
        row[3].text = f"{jsd_sdbpa:.4f}"
        
        if p_sdbpa == 0:
            row[4].text = "< 0.001"
        else:
            row[4].text = f"{p_sdbpa:.4f}"
            
    # --- 4. Conclusion ---
    doc.add_heading('4. Conclusion', level=1)
    add_paragraph(doc,
        "S-DBPA addresses a critical flaw in current LLM auditing: the fragility of single-prompt testing. "
        "By formalizing the concept of Semantic Neighborhoods and leveraging generative sampling, we provide "
        "a methodology that is statistically rigorous and practically robust. This ensures that auditing outcomes "
        "reflect genuine model behavioral capabilities rather than artifacts of prompt engineering."
    )

    doc.save(DOCX_FILE)
    print(f"Successfully created Word document at: {DOCX_FILE}")

if __name__ == "__main__":
    main()
